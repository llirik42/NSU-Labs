# Задание

1. Написать 2 программы (последовательную и параллельную с использованием MPI) на языке C/C++, которые реализуют итерационный алгоритм решения системы линейных алгебраических уравнений вида
$$Ax = b$$
используя `метод сопряжённых градиентов`. Здесь *A* – матрица размером *N*×*N*, *x* и *b* – векторы длины *N*. Тип элементов – double, а преобразование решения на каждом шаге задается формулами 
$$r_0 = b - Ax_0$$
$$z_0=r_0$$
$$\alpha_{n+1}=\frac{(r_n, r_n)}{(Az_n, z_n)}$$
$$x_{n+1}=x_n + \alpha_{n+1}z_n$$
$$r_{n+1}=r_n-\alpha_{n+1} A z_n$$
$$\beta_{n+1}=\frac{(r_{n+1}, r_{n+1})}{(r_n, r_n)}$$
$$z_{n+1}=r_{n+1} + \beta_{n+1} z_n$$
Критерий завершения отсчёта можно взять следующий
$$\frac{||r_n||_2}{||b||_2} < \varepsilon$$
где
$$||u||_2 = \sqrt{\sum\_{k=1}^{N} u_k^2}$$
2. Параллельную программу реализовать с тем условием, что матрица *A* и вектор *b* инициализируются на каком-либо одном процессе, а затем матрица *A* «разрезается» по строкам на близкие по размеру, возможно не одинаковые, части, а вектор *b* раздается каждому процессу. Уделить внимание тому, чтобы при запуске программы на различном
числе MPI-процессов решалась одна и та же задача (исходные данные заполнялись одинаковым образом).
3. Замерить время работы последовательного варианта программы, а также время работы параллельного при использовании различного числа процессорных ядер.
4. Построить графики зависимости времени работы программы, ускорения и эффективности распараллеливания от числа используемых ядер. Исходные данные, параметры *N* и *ε* подобрать таким образом, чтобы решение задачи на одном ядре занимало не менее 30 секунд.
5. Выполнить профилирование двух вариантов программы с помощью `jumpshot` или `ITAC` (Intel Trace Analyzer and Collecter) при использовании 16-и или 24-х ядер.

**Ускорение**
$$S_p = \frac{T_{seq}}{T_p}$$

где $T_{seq}$ — время работы последовательной программы, $T_p$ - время работы параллельной программы на *p* процессах.

**Эффективность**
$$E_p = 100\\% \cdot \frac{S_p}{p}$$

# Компиляция
Последовательная программа может быть скомпилирована обычным образом (здесь и далее ключ *-lm* нужен для использования библиотеки «math.h»):

    $ gcc sequential.c utils.c -o sequential -lm

или

    $ icc sequential.c utils.c -o sequential -lm

Параллельные программы нужно компилировать несколько иначе. Можно использовать различные компиляторы

    $ mpicc parallel.c utils.c -o parallel -lm

    $ mpiicc parallel.c utils.c -o parallel -lm

Первый вариант использует надстройку над компилятором `gcc`, второй — над компилятором `icc`. Аналогично можно использовать компиляторы `g++` и `icx`, однако в этом не было нужды, поскольку весь код был написан на языке C, а не на C++. 

# Запуск
Последовательная программа запускается как обычная программа

    $ ./sequential

Параллельные программы нужно запускать, используя одну из следующих команд

    $ mpiexec -n x ./parallel

    $ mpirun -np x ./parallel

Здесь *x* — число процессов, которое должно быть использовано в программе. Эти варианты запуска практически аналогичны, так что можно выбрать любой.

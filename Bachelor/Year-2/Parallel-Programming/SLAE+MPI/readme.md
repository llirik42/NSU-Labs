# Параллельная реализация решения системы линейных алгебраических уравнений с помощью MPI

## Задание

1. Написать 2 программы (последовательную и параллельную с использованием *MPI*) на языке C/C++, которые реализуют итерационный алгоритм решения системы линейных алгебраических уравнений вида

```math
Ax = b
```

используя *метод сопряжённых градиентов*. Здесь $A$ – матрица размером $N$ × $N$, $x$, $b$ – векторы длины $N$. Тип элементов – `double`, а преобразование решения на каждом шаге задается формулами

```math
r_0 = b - A x_0
```

```math
z_0 = r_0
```

```math
\alpha_{n + 1} = \frac{(r_n, r_n)}{(A z_n, z_n)}
```

```math
x_{n + 1} = x_n + \alpha_{n + 1} z_n
```

```math
r_{n + 1} = r_n - \alpha_{n + 1} A z_n
```

```math
\beta_{n + 1} = \frac{(r_{n + 1}, r_{n + 1})}{(r_n, r_n)}
```

```math
z_{n + 1} = r_{n + 1} + \beta_{n + 1} z_n
```

Критерий завершения отсчёта можно взять следующий

```math
\frac{\|r_n\|_2}{\|b\|_2} < \varepsilon
```

где

```math
\|u\|_2 = \sqrt{\sum\limits_{k=1}^{N} u_k^2}
```

2. Параллельную программу реализовать с тем условием, что матрица $A$ и вектор $b$ инициализируются на каком-либо одном процессе, а затем матрица $A$ "разрезается" по строкам на близкие по размеру, возможно не одинаковые, части, а вектор $b$ раздается каждому процессу. Уделить внимание тому, чтобы при запуске программы на различном числе *MPI*-процессов решалась одна и та же задача (исходные данные заполнялись одинаковым образом).
3. Замерить время работы последовательного варианта программы, а также время работы параллельного при использовании различного числа процессорных ядер.
4. Построить графики зависимости времени работы программы, ускорения и эффективности распараллеливания от числа используемых ядер. Исходные данные, параметры $N$ и $ε$ подобрать таким образом, чтобы решение задачи на одном ядре занимало не менее 30 секунд.
5. Выполнить профилирование двух вариантов программы с помощью *jumpshot* или *ITAC* при использовании 16-и или 24-х ядер.

### Ускорение

```math
S_p = \frac{T_{seq}}{T_p}
```

где $T_{seq}$ — время работы последовательной программы, $T_p$ - время работы параллельной программы на $p$ процессах.

### Эффективность

```math
E_p = 100\% \cdot \frac{S_p}{p}
```
